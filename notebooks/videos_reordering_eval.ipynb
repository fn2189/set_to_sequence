{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual imports\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "#import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import pickle\n",
    "from glob import glob\n",
    "import random\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.backends import cudnn\n",
    "from torch.optim import Adam\n",
    "\n",
    "#tensorboard\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "#my modules\n",
    "sys.path.append('../')\n",
    "sys.path.append('../scripts')\n",
    "from scripts.dataset import DigitsDataset, WordsDataset, VideosDataset\n",
    "from scripts.order_matters import ReadProcessWrite\n",
    "from scripts.digits_reordering import create_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CLASSES = {'linear': DigitsDataset, 'words': WordsDataset, 'videos': VideosDataset}\n",
    "LETTERS = 'abcdefghijklmnopqrstuvwxyz'\n",
    "PICKLE_FILE = '../../s3-drive/set_to_sequence/video_reordering_18374_3937_5_2019-06-18_11:45:26.327081.pkl' \n",
    "RESUME = '../checkpoints/1/ep_100_map_inf_latest.pth.tar'\n",
    "BATCH_SIZE = 128\n",
    "HIDDEN_DIMS = [256]\n",
    "LSTM_STEPS = 10\n",
    "READER = 'videos'\n",
    "INPUT_DIM = 1280\n",
    "DROPOUT = 0.2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    USE_CUDA = True\n",
    "    print('Using GPU, %i devices.' % torch.cuda.device_count())\n",
    "else:\n",
    "    USE_CUDA = False\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "ARGS =parser.parse_args(args=[])\n",
    "ARGS.batch_size = BATCH_SIZE\n",
    "ARGS.hidden_dims = HIDDEN_DIMS\n",
    "ARGS.lstm_steps = LSTM_STEPS\n",
    "ARGS.input_dim = INPUT_DIM\n",
    "ARGS.reader = READER\n",
    "ARGS.dropout = DROPOUT\n",
    "ARGS.resume = RESUME\n",
    "ARGS.USE_CUDA = USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Training\n",
    "    correct_orders = 0\n",
    "    total_orders = 0\n",
    "    loader_len = len(test_loader)\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        X, Y, additional_dict = data\n",
    "        boundaries_lists = additional_dict['blocks_boundaries']\n",
    "        \n",
    "        \n",
    "        # Transfer to GPU\n",
    "        device = f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'\n",
    "        X, Y = X.to(device).float(), Y.to(device)\n",
    "        #X, Y = X.cuda().float(), Y.cuda()\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, pointers, hidden = model(X)\n",
    "        \n",
    "        outputs = outputs.contiguous().view(-1, outputs.size()[-1])\n",
    "        #print(f'outputs: {outputs.size()}, Y: {Y.size()}')\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        if args.reader == 'words':\n",
    "            words = X_to_words(X.cpu())\n",
    "            #inds_x = np.tile(np.array(range(words.shape[0])), [words.shape[1], 1]).T\n",
    "            predicted_inds = pointers.cpu().data.numpy()\n",
    "            real_inds = Y.cpu().data.numpy()\n",
    "            for i in range(real_inds.shape[0]):\n",
    "                print(f' Predicted Words order: {words[i, predicted_inds[i,:]]}')\n",
    "                print(f' Real Words order: {words[i, real_inds[i,:]]}\\n')\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        print(f'Predictions: {pointers}')\n",
    "        print(f'Real orders: {Y}')\n",
    "        \n",
    "            \n",
    "\n",
    "        ###We display the predicted order and real order for the idx-th video of each batch\n",
    "        idx = 28\n",
    "        videofile = additional_dict['filename'][idx]\n",
    "        print(f'Videofile: {videofile}, Y shape: {Y.shape}, len(boundaries_lists): {len(boundaries_lists)}')\n",
    "        basename = os.path.basename(videofile)\n",
    "        video = skvideo.io.vread(videofile)\n",
    "        \n",
    "        predicted_frame_blocks = [range(boundaries_lists[i-1][idx],boundaries_lists[i][idx]) for i in range(1,len(boundaries_lists))]\n",
    "        predicted_frame_blocks = [predicted_frame_blocks[i] for i in Y[idx]]\n",
    "\n",
    "        predicted_frame_order = [val for sublist in predicted_frame_blocks for val in sublist]\n",
    "\n",
    "        reordered_video = video[predicted_frame_order,:,:,:]\n",
    "        \n",
    "        print(f'video n frames: {video.shape[0]}, reordered_video n frames: {len(predicted_frame_order)}')\n",
    "        \n",
    "        predicted_filename = f'../data/predicted_videos/{basename}'\n",
    "        skvideo.io.vwrite(predicted_filename, reordered_video)\n",
    "\n",
    "        #show_video(videofile)\n",
    "\n",
    "        #show_video(predicted_filename)\n",
    "        \n",
    "\n",
    "        for _ in range(pointers.size(0)):\n",
    "            total_orders += 1\n",
    "            if Y[_,:].equal( pointers[_,:]):\n",
    "                correct_orders +=1\n",
    "                \n",
    "    print(f'Fraction of perfectly sorted sets: {correct_orders/total_orders}')\n",
    "\n",
    "\n",
    "def X_to_words(X):\n",
    "    \"\"\"\n",
    "    X is of shape (batch, n_seq, max_word_length, vocab_size)\n",
    "    \"\"\"\n",
    "    array = X.data.numpy()\n",
    "    words =  np.ndarray((array.shape[0], array.shape[1]), dtype=object)\n",
    "    words.fill('')\n",
    "    #print(f'Words shape: {words.shape}')\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            for k in range(X.shape[2]):\n",
    "                if max(X[i,j,k,:]) == 1:\n",
    "                    words[i,j] += LETTERS[np.argmax(X[i,j,k,:])]\n",
    "                else:\n",
    "                    pass\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    ###emptying the ../data/predicted_videos folder\n",
    "    subprocess.run(['rm', '-rf', '../data/predicted_videos/*'])\n",
    "    \n",
    "    with open(PICKLE_FILE, 'rb') as f:\n",
    "        dict_data = pickle.load(f)\n",
    "        \n",
    "    \n",
    "    #runs = glob(args.saveprefix+'/*')\n",
    "    #it = len(runs) + 1\n",
    "    #writer = SummaryWriter(os.path.join(args.tensorboard_saveprefix, str(it)))\n",
    "    #writer.add_text('Metadata', 'Run {} metadata :\\n{}'.format(it, args,))\n",
    "    \n",
    "    dataset_class = DATASET_CLASSES[READER]\n",
    "    \n",
    "    test_ds = dataset_class(dict_data['test'])\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            test_ds,\n",
    "            batch_size=BATCH_SIZE, shuffle=True,\n",
    "            num_workers=4, pin_memory=True)\n",
    "    \n",
    "    \n",
    "    model = create_model(ARGS)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if USE_CUDA:\n",
    "        device = torch.cuda.current_device()\n",
    "        #model.cuda()\n",
    "        device = f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'\n",
    "        model.to(device)\n",
    "        net = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "        cudnn.benchmark = True\n",
    "        \n",
    "    test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video(filename):\n",
    "    video = io.open(filename, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return HTML(data='''<video alt=\"test\" controls>\n",
    "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_videos = glob('../data/predicted_videos/*')\n",
    "predicted_videofile = predicted_videos[1]\n",
    "basename = os.path.basename(predicted_videofile)\n",
    "\n",
    "original_videofile = f'../../s3-drive/RLY/RLYMedia/{basename}'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(original_videofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(predicted_videofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (virtualenv_set2seq)",
   "language": "python",
   "name": "virtualenv_set2seq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
